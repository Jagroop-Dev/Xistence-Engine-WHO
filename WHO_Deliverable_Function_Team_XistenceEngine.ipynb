{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0416558c-055a-4693-9149-5f4b8e7d95d7",
      "metadata": {
        "id": "0416558c-055a-4693-9149-5f4b8e7d95d7"
      },
      "source": [
        "# FINAL FUNCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"display: flex;\">\n",
        "  <img src=\"https://github.com/Jagroop-Dev/Xistence-Engine-WHO/blob/main/WHOl1.png?raw=true\"\n",
        "       width=\"300px\"\n",
        "       height=\"300px\"\n",
        "       style=\"margin-right: 50px;\" />\n",
        "  \n",
        "  <img src=\"https://github.com/Jagroop-Dev/Xistence-Engine-WHO/blob/main/WHO%20LOGO.png?raw=true\"\n",
        "       width=\"300px\"\n",
        "       height=\"300px\" />\n",
        "</div>\n",
        "\n",
        "# Team 5: Xsistence Engine Exploratory Data Analysis\n",
        "        \n",
        "### By Jagroop Singh, Graciela Diwa and Joachim Boyden"
      ],
      "metadata": {
        "id": "02TCl_Y5GsvE"
      },
      "id": "02TCl_Y5GsvE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23948e31-240e-4872-908f-bd0c228bd290",
      "metadata": {
        "id": "23948e31-240e-4872-908f-bd0c228bd290"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = pd.read_csv('https://raw.githubusercontent.com/Jagroop-Dev/Xistence-Engine-WHO/refs/heads/main/X_train.csv')"
      ],
      "metadata": {
        "id": "W9wa4iCSiI3e"
      },
      "id": "W9wa4iCSiI3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f48d1fea"
      },
      "source": [
        "### `valid_input` Function Explanation\n",
        "\n",
        "This function is a used to validate user input. It repeatedly prompts the user for the correct input until a valid response is received, based on specified criteria like data type, allowed options, and value ranges."
      ],
      "id": "f48d1fea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c59d9eb-f109-4de6-a1b4-9b8202a6a1fc",
      "metadata": {
        "id": "6c59d9eb-f109-4de6-a1b4-9b8202a6a1fc"
      },
      "outputs": [],
      "source": [
        "def valid_input(ui, valid_options=None, data_type=int, min_value=None, max_value=None):\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(ui)\n",
        "            if data_type == int:\n",
        "                user_input = int(user_input)\n",
        "            elif data_type == float:\n",
        "                user_input = float(user_input)\n",
        "\n",
        "            # Add check for negative values\n",
        "            if data_type in [int, float] and user_input < 0:\n",
        "                print(\"Please enter a non-negative value.\")\n",
        "            elif min_value is not None and user_input < min_value:\n",
        "                print(f\"Please enter a value greater than or equal to {min_value}.\")\n",
        "            elif max_value is not None and user_input > max_value:\n",
        "                print(f\"Please enter a value less than or equal to {max_value}.\")\n",
        "            elif valid_options and user_input not in valid_options:\n",
        "                print(f\"Please choose one of the: {valid_options}\")\n",
        "            else:\n",
        "                return user_input\n",
        "        except ValueError:\n",
        "            print(f\"Please enter a valid {data_type.__name__}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dc9f682"
      },
      "source": [
        "### `ask_questions` Function Explanation\n",
        "\n",
        "This is a very simple function that takes a `feature_name` as input and returns a formatted string to prompt the user for that feature's value."
      ],
      "id": "2dc9f682"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad05d57-f827-4ea0-8e9a-36f5eef6fd85",
      "metadata": {
        "id": "5ad05d57-f827-4ea0-8e9a-36f5eef6fd85"
      },
      "outputs": [],
      "source": [
        "def ask_questions(feature_name):\n",
        "    return f\"Please enter your {feature_name}: \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19d53da9"
      },
      "source": [
        "### `ask_consent` Function Explanation\n",
        "\n",
        "This function asks the user for their consent to use advanced population data for the advanced model. It prompts the user with a Y/N question and returns a string indicating whether the 'advanced_model' or 'ethical_model' should be used based on the user's response."
      ],
      "id": "19d53da9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6db90a6-9d89-495f-a194-afa6de99723a",
      "metadata": {
        "id": "f6db90a6-9d89-495f-a194-afa6de99723a"
      },
      "outputs": [],
      "source": [
        "def ask_consent():\n",
        "    consent = input(\"Do you consent to using advanced population data which may be protected information, for better accuracy?(Y/N)\").strip().lower()\n",
        "    if consent == \"y\":\n",
        "        print(\"You have selected to use the advanced model. \")\n",
        "        return 'advanced_model'\n",
        "    else:\n",
        "        print(\"You have selected to use the standard model. \")\n",
        "        return 'ethical_model'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbc4a4cc"
      },
      "source": [
        "### `encode_region` Function Explanation\n",
        "\n",
        "This function takes a region name as input and returns the corresponding one-hot encoded column name used in the models. If the region is not recognized, it returns `None`."
      ],
      "id": "fbc4a4cc"
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_region(region):\n",
        "    regions = {\n",
        "        \"Middle East\": \"Region_Middle East\",\n",
        "        \"European Union\": \"Region_European Union\",\n",
        "        \"Asia\": \"Region_Asia\",\n",
        "        \"North America\": \"Region_North America\",\n",
        "        \"Central America and Caribbean\": \"Region_Central America and Caribbean\",\n",
        "        \"South America\": \"Region_South America\",\n",
        "        \"Rest of Europe\": \"Region_Rest of Europe\",\n",
        "        \"Africa\": \"Region_Africa\",\n",
        "        \"Oceania\": \"Region_Oceania\"\n",
        "    }\n",
        "    return regions.get(region, None)"
      ],
      "metadata": {
        "id": "0OL97W7IfDD9"
      },
      "id": "0OL97W7IfDD9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71ced7bd"
      },
      "source": [
        "### `ask_features` Function Explanation\n",
        "\n",
        "This function is responsible for prompting the user to enter the values for the features required by the chosen model (ethical or advanced). It uses the `valid_input` function to ensure the inputs are of the correct data type and within valid ranges where specified. It also handles the encoding of the economy status and region based on user input."
      ],
      "id": "71ced7bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8210e611-67d2-49b7-9421-ef0d20aa11d2",
      "metadata": {
        "id": "8210e611-67d2-49b7-9421-ef0d20aa11d2"
      },
      "outputs": [],
      "source": [
        "def ask_features(model_choice, user_answers):\n",
        "    ethical_model_features = [\n",
        "        \"Economy status (Developed or Developing)\",\n",
        "        \"GDP per Capita\", \"Under five deaths\", \"Adult mortality\",\n",
        "        \"Population (millions)\", \"Infant deaths\", \"Year\"\n",
        "    ]\n",
        "\n",
        "    advanced_model_features = [\n",
        "        \"Alcohol consumption\", \"Hepatitis B\", \"BMI\", \"Polio\", \"Diphtheria\",\n",
        "        \"Incidents HIV\", \"Thinness ten nineteen years\", \"Thinness five nine years\", \"Schooling\"\n",
        "    ]\n",
        "\n",
        "    user_inputs = {}\n",
        "\n",
        "    feature_prompts = {\n",
        "        \"Economy status (Developed or Developing)\": \"Please enter the Economy status (Developed or Developing): \",\n",
        "        \"GDP per Capita\": \"Please enter the Gross Domestic Product per capita (in USD): \",\n",
        "        \"Under five deaths\": \"Please enter the Number of under-five deaths per 1000 population: \",\n",
        "        \"Adult mortality\": \"Please enter the Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population): \",\n",
        "        \"Population (millions)\": \"Please enter the Population of the country (in millions): \",\n",
        "        \"Infant deaths\": \"Please enter the Number of Infant Deaths per 1000 population: \",\n",
        "        \"Year\": \"Please enter the Year (between 2000 and 2024): \",\n",
        "        \"Alcohol consumption\": \"Please enter the Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol): \",\n",
        "        \"Hepatitis B\": \"Please enter the Hepatitis B (HepB) immunization coverage among 1-year-olds (%): \",\n",
        "        \"BMI\": \"Please enter the Average Body Mass Index of entire population: \",\n",
        "        \"Polio\": \"Please enter the Polio (Pol3) immunization coverage among 1-year-olds (%): \",\n",
        "        \"Diphtheria\": \"Please enter the Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%): \",\n",
        "        \"Incidents HIV\": \"Please enter the Deaths per 1 000 live births HIV/AIDS (0-4 years): \",\n",
        "        \"Thinness ten nineteen years\": \"Please enter the Prevalence of thinness among children and adolescents for Age 10 to 19 (%): \",\n",
        "        \"Thinness five nine years\": \"Please enter the Prevalence of thinness among children for Age 5 to 9(%): \",\n",
        "        \"Schooling\": \"Please enter the Number of years of Schooling(years): \"\n",
        "    }\n",
        "\n",
        "\n",
        "    for feature in ethical_model_features:\n",
        "        prompt = feature_prompts.get(feature, f\"Please enter your {feature}: \")\n",
        "        if feature == \"Economy status (Developed or Developing)\":\n",
        "            economy_status = valid_input(\n",
        "                prompt,\n",
        "                valid_options=['Developed', 'Developing'],\n",
        "                data_type=str\n",
        "            )\n",
        "            user_inputs['Economy_status_Developed'] = 1 if economy_status == \"Developed\" else 0\n",
        "\n",
        "            user_inputs['Economy_status_Developing'] = 1 if economy_status == \"Developing\" else 0\n",
        "        elif feature == \"GDP per Capita\":\n",
        "            user_inputs['GDP_per_capita'] = valid_input(prompt, data_type=float)\n",
        "        elif feature == \"Year\":\n",
        "            user_inputs[feature] = valid_input(prompt, data_type=int, min_value=2000, max_value=2024) # Changed max_value to 2024\n",
        "        else:\n",
        "            user_inputs[feature] = valid_input(prompt, data_type=float)\n",
        "\n",
        "\n",
        "    if model_choice == 'advanced_model':\n",
        "        for feature in advanced_model_features:\n",
        "            prompt = feature_prompts.get(feature, f\"Please enter your {feature}: \")\n",
        "            if feature == \"Alcohol consumption\":\n",
        "                user_inputs['Alcohol_consumption'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Hepatitis B\":\n",
        "                 user_inputs['Hepatitis_B'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"BMI\":\n",
        "                 user_inputs['BMI'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Polio\":\n",
        "                 user_inputs['Polio'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Diphtheria\":\n",
        "                 user_inputs['Diphtheria'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Incidents HIV\":\n",
        "                 user_inputs['Incidents_HIV'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Thinness ten nineteen years\":\n",
        "                 user_inputs['Thinness_ten_nineteen_years'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Thinness five nine years\":\n",
        "                 user_inputs['Thinness_five_nine_years'] = valid_input(prompt, data_type=float)\n",
        "            elif feature == \"Schooling\":\n",
        "                 user_inputs['Schooling'] = valid_input(prompt, data_type=float)\n",
        "            else:\n",
        "                user_inputs[feature] = valid_input(prompt, data_type=float) # Catch any others\n",
        "\n",
        "\n",
        "    region = user_answers['Region']\n",
        "    encoded_region = encode_region(region)\n",
        "    if encoded_region:\n",
        "        user_inputs[encoded_region] = 1\n",
        "\n",
        "\n",
        "        regions_list = [\n",
        "            \"Region_Middle East\", \"Region_European Union\", \"Region_Asia\",\n",
        "            \"Region_North America\", \"Region_Central America and Caribbean\",\n",
        "            \"Region_South America\", \"Region_Rest of Europe\", \"Region_Africa\",\n",
        "            \"Region_Oceania\"\n",
        "        ]\n",
        "        for reg in regions_list:\n",
        "            if reg != encoded_region:\n",
        "                user_inputs[reg] = 0\n",
        "    else:\n",
        "        print(\"Invalid region selected!\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "    if 'Region' in user_inputs:\n",
        "        del user_inputs['Region']\n",
        "\n",
        "\n",
        "    return user_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ad298c"
      },
      "source": [
        "### `make_prediction` Function Explanation\n",
        "\n",
        "This function takes a model dictionary (containing feature coefficients) and a DataFrame of input data and calculates the predicted life expectancy."
      ],
      "id": "93ad298c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ebf0ab-981b-44c0-9b70-be7fef739fe3",
      "metadata": {
        "id": "e2ebf0ab-981b-44c0-9b70-be7fef739fe3"
      },
      "outputs": [],
      "source": [
        "def make_prediction(model: dict, data: pd.DataFrame) -> float:\n",
        "\n",
        "    if 'const' not in data.columns:\n",
        "        data = sm.add_constant(data, has_constant='add')\n",
        "\n",
        "    prediction = sum([model.get(feature, 0) * data[feature][0] for feature in model.keys() if feature in data.columns])\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb9345e1"
      },
      "source": [
        "### `robust_scale` Function Explanation\n",
        "\n",
        "This function fits the scaler on the training data (`X_train`) and then transforms the `input_data`."
      ],
      "id": "cb9345e1"
    },
    {
      "cell_type": "code",
      "source": [
        "def robust_scale(train: pd.DataFrame, input_data: dict) -> dict:\n",
        "    rob = RobustScaler()\n",
        "\n",
        "\n",
        "    numeric_cols = train.select_dtypes(include=['number']).columns\n",
        "    scaler = rob.fit(train[numeric_cols])\n",
        "\n",
        "\n",
        "    input_df = pd.DataFrame([input_data], columns=numeric_cols)\n",
        "\n",
        "\n",
        "    scaled_input = scaler.transform(input_df)\n",
        "\n",
        "\n",
        "    scaled_dict = pd.DataFrame(scaled_input, columns=numeric_cols).to_dict(orient='records')[0]\n",
        "\n",
        "    return scaled_dict"
      ],
      "metadata": {
        "id": "e1ss_ks-fLef"
      },
      "id": "e1ss_ks-fLef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bcc233e"
      },
      "source": [
        "### `feature_eng` Function Explanation\n",
        "\n",
        "This function performs feature engineering on the user's input data. This includes applying transformations like log scaling and then scaling the numerical features using the `robust_scale` function. It ensures the final DataFrame has all the necessary columns for the prediction models."
      ],
      "id": "8bcc233e"
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_eng(df):\n",
        "    print(f\"Original user inputs: {df}\")\n",
        "\n",
        "\n",
        "    df_processed = df.copy()\n",
        "\n",
        "\n",
        "    df_processed['GDP_per_capita'] = np.log(df_processed['GDP_per_capita'] + 1)\n",
        "    df_processed['Population_mln'] = np.log(df_processed['Population_mln'] + 1)\n",
        "\n",
        "\n",
        "\n",
        "    numerical_cols_for_scaling = ['GDP_per_capita', 'Under_five_deaths', 'Adult_mortality', 'Population_mln', 'Infant_deaths', 'Year']\n",
        "\n",
        "\n",
        "    df_numerical_for_scaling = df_processed[numerical_cols_for_scaling]\n",
        "\n",
        "    scaled_df_values = robust_scale(X_train[numerical_cols_for_scaling], df_numerical_for_scaling.iloc[0].to_dict())\n",
        "\n",
        "\n",
        "\n",
        "    for col in numerical_cols_for_scaling:\n",
        "      df_processed[col] = scaled_df_values[col]\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col not in df_processed.columns:\n",
        "            df_processed[col] = df[col]\n",
        "\n",
        "\n",
        "\n",
        "    df_processed = sm.add_constant(df_processed, has_constant='add')\n",
        "\n",
        "\n",
        "\n",
        "    return df_processed"
      ],
      "metadata": {
        "id": "6BLXHwxGfM6D"
      },
      "id": "6BLXHwxGfM6D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Coef\n",
        "\n",
        "This function performs feature engineering on the user's input data. This includes applying transformations like log scaling and then scaling the numerical features using the `robust_scale` function. It ensures the final DataFrame has all the necessary columns for the prediction models."
      ],
      "metadata": {
        "id": "-gYYeZpfVH4L"
      },
      "id": "-gYYeZpfVH4L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07689bf1-8cb7-4eda-9619-3a8825e31809",
      "metadata": {
        "id": "07689bf1-8cb7-4eda-9619-3a8825e31809"
      },
      "outputs": [],
      "source": [
        "advanced_model = {'const'                  :70.676838,\n",
        "'Year'                                     :0.257635,\n",
        "'Under_five_deaths'                       :-2.883196,\n",
        "'Infant_deaths'                           :-1.764888,\n",
        "'Adult_mortality'                         :-6.114546,\n",
        "'Alcohol_consumption'                     :-0.207149,\n",
        "'Hepatitis_B'                             :-0.142623,\n",
        "'BMI'                                     :-0.377977,\n",
        "'GDP_per_capita'                           :1.084308,\n",
        "'Population_mln'                           :0.279958,\n",
        "'Schooling'                                :0.415376,\n",
        "'Economy_status_Developing'               :-2.581425,\n",
        "'Region_Asia'                              :0.251088,\n",
        "'Region_Central America and Caribbean'     :1.994919,\n",
        "'Region_European Union'                   :-0.606132,\n",
        "'Region_Middle East'                       :0.071231,\n",
        "'Region_North America'                    :0.242322,\n",
        "'Region_Oceania'                          :-0.578854,\n",
        "'Region_Rest of Europe'                    :0.552260,\n",
        "'Region_South America'                     :1.590394,\n",
        "'Polio'                                    :0.140878}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-uhJZym2DO2S",
      "metadata": {
        "id": "-uhJZym2DO2S"
      },
      "outputs": [],
      "source": [
        "ethical_model = {'GDP_per_capita'                      : 1.0343,\n",
        "                 'Under_five_deaths'                   : -2.9628,\n",
        "                 'Adult_mortality'                     : -6.0962,\n",
        "                 'const'                               : 70.7061,\n",
        "                 'Economy_status_Developed'            : 2.8228,\n",
        "                 'Population_mln'                      : 0.3300,\n",
        "                 'Infant_deaths'                       : -1.7405,\n",
        "                 'Year'                                : 0.2556,\n",
        "                 'Region_Asia'                         : 0.4594,\n",
        "                 'Region_Central America and Caribbean': 1.8377,\n",
        "                 'Region_European Union'               : -0.8370,\n",
        "                 'Region_Middle East'                  : -0.0440,\n",
        "                 'Region_North America'                : 0.0686,\n",
        "                 'Region_Oceania'                      : -0.7979,\n",
        "                 'Region_Rest of Europe'               : 0.5545,\n",
        "                 'Region_South America'                : 1.4445}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166a06c5"
      },
      "source": [
        "### `standardize_feature_names` Function Explanation\n",
        "\n",
        "This function standardizes the feature names from the user input (which might have spaces or different capitalization) to match the format used in the model dictionaries and the DataFrame columns."
      ],
      "id": "166a06c5"
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_feature_names(user_inputs):\n",
        "\n",
        "    standardized_inputs = {}\n",
        "\n",
        "    feature_map = {\n",
        "        \"GDP per Capita\": \"GDP_per_capita\",\n",
        "        \"Under five deaths\": \"Under_five_deaths\",\n",
        "        \"Adult mortality\": \"Adult_mortality\",\n",
        "        \"Population (millions)\": \"Population_mln\",\n",
        "        \"Infant deaths\": \"Infant_deaths\",\n",
        "        \"Economy status (Developed or Developing)\": \"Economy_status_Developed\",\n",
        "        \"Year\": \"Year\",\n",
        "        \"Region\": \"Region\",\n",
        "        \"BMI\": \"BMI\"\n",
        "    }\n",
        "\n",
        "    for feature, value in user_inputs.items():\n",
        "\n",
        "        standardized_inputs[feature_map.get(feature, feature)] = value\n",
        "\n",
        "    return standardized_inputs"
      ],
      "metadata": {
        "id": "9JM6GXBMfPR_"
      },
      "id": "9JM6GXBMfPR_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6cc5cf7"
      },
      "source": [
        "### `life_expectancy_predictor` Function Explanation\n",
        "\n",
        "This is the main function that makes use of all of the various functions of getting user input, processing it, and making a life expectancy prediction using either the ethical or advanced model."
      ],
      "id": "a6cc5cf7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27788a61-a223-44dc-ae80-f69f62fce020",
      "metadata": {
        "id": "27788a61-a223-44dc-ae80-f69f62fce020"
      },
      "outputs": [],
      "source": [
        "def life_expectancy_predictor():\n",
        "    user_answers = {}\n",
        "\n",
        "    model_choice = ask_consent()\n",
        "    print(\"Model choice:\", model_choice)\n",
        "\n",
        "    print(\"Please select your region by choosing the correct number:\\n\")\n",
        "    regions = {\n",
        "        1: \"Middle East\",\n",
        "        2: \"European Union\",\n",
        "        3: \"Asia\",\n",
        "        4: \"North America\",\n",
        "        5: \"Central America and Caribbean\",\n",
        "        6: \"South America\",\n",
        "        7: \"Rest of Europe\",\n",
        "        8: \"Africa\",\n",
        "        9: \"Oceania\"\n",
        "    }\n",
        "\n",
        "    for key, value in regions.items():\n",
        "        print(f\"{key}. {value}\")\n",
        "\n",
        "    user_region = valid_input(\n",
        "        \"Enter your choice: \",\n",
        "        valid_options=regions.keys(),\n",
        "        data_type=int\n",
        "    )\n",
        "\n",
        "\n",
        "    user_answers['Region'] = regions[user_region]\n",
        "\n",
        "\n",
        "    user_inputs = ask_features(model_choice, user_answers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    standardized_user_inputs = standardize_feature_names(user_inputs)\n",
        "\n",
        "\n",
        "\n",
        "    df = pd.DataFrame([standardized_user_inputs])\n",
        "\n",
        "\n",
        "\n",
        "    engineered_user_inputs = feature_eng(df)\n",
        "\n",
        "\n",
        "    if model_choice == 'advanced_model':\n",
        "        prediction = make_prediction(advanced_model,engineered_user_inputs)\n",
        "    else:\n",
        "        prediction = make_prediction(ethical_model, engineered_user_inputs)\n",
        "\n",
        "\n",
        "    print(f\"Predicted Life Expectancy: {prediction:.2f} years\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "life_expectancy_predictor()"
      ],
      "metadata": {
        "id": "CKz3ghj5Twvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "b1c30465-15c3-417a-af1f-0a4f098e944a"
      },
      "id": "CKz3ghj5Twvl",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you consent to using advanced population data which may be protected information, for better accuracy?(Y/N)n\n",
            "You have selected to use the standard model. \n",
            "Model choice: ethical_model\n",
            "Please select your region by choosing the correct number:\n",
            "\n",
            "1. Middle East\n",
            "2. European Union\n",
            "3. Asia\n",
            "4. North America\n",
            "5. Central America and Caribbean\n",
            "6. South America\n",
            "7. Rest of Europe\n",
            "8. Africa\n",
            "9. Oceania\n",
            "Enter your choice: 1\n",
            "Please enter the Economy status (Developed or Developing): Developed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-91-2455896538.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlife_expectancy_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-77-3034805005.py\u001b[0m in \u001b[0;36mlife_expectancy_predictor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0muser_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-84-68227416.py\u001b[0m in \u001b[0;36mask_features\u001b[0;34m(model_choice, user_answers)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0muser_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Economy_status_Developing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0meconomy_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Developing\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GDP per Capita\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0muser_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GDP_per_capita'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0muser_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Changed max_value to 2024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-80-3603469195.py\u001b[0m in \u001b[0;36mvalid_input\u001b[0;34m(ui, valid_options, data_type, min_value, max_value)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}